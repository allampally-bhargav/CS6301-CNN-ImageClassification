# -*- coding: utf-8 -*-
"""CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/130vMf-kmzHovobUQcgCpfqjP6lb7SW8p
"""

# 
# LOGISTICS
#
#    Name: Bhargav Allampally
#    UTD ID - BXA180005
#DESCRIPTION
#
#    Image classification in PyTorch for ImageNet reduced to 100 classes and
#    down sampled such that the short side is 64 pixels and the long side is
#    >= 64 pixels
#
#    This script achieved a best accuracy of ??.??% on epoch ?? with a learning
#    rate at that point of ?.????? and time required for each epoch of ~ ??? s
#
# INSTRUCTIONS
#
#    1. Go to Google Colaboratory: https://colab.research.google.com/notebooks/welcome.ipynb
#    2. File - New Python 3 notebook
#    3. Cut and paste this file into the cell (feel free to divide into multiple cells)
#    4. Runtime - Run all
#
# NOTES
#
#    0. For a mapping of category names to directory names see:
#       https://gist.github.com/aaronpolhamus/964a4411c0906315deb9f4a3723aac57
#
#    1. The original 2012 ImageNet images are down sampled such that their short
#       side is 64 pixels (the other side is >= 64 pixels) and only 100 of the
#       original 1000 classes are kept.
#
#    2. Build and train a RegNetX image classifier modified as follows:
#
#       - Set stride = 1 (instead of stride = 2) in the stem
#       - Replace the first stride = 2 down sampling building block in the
#         original network by a stride = 1 normal building block
#       - The fully connected layer in the decoder outputs 100 classes instead
#         of 1000 classes
#
#       The original RegNetX takes in 3x224x224 input images and generates Nx7x7
#       feature maps before the decoder, this modified RegNetX will take in
#       3x56x56 input images and generate Nx7x7 feature maps before the decoder.
#       For reference, an implementation of this network took ~ 112 s per epoch
#       for training, validation and checkpoint saving on Sep 27, 2020 using a
#       free GPU runtime in Google Colab.
#
################################################################################

################################################################################
#
# IMPORT
#
################################################################################

# torch
import torch
import torch.nn       as     nn
import torch.optim    as     optim
from   torch.autograd import Function
import torch.nn.functional as F

# torch utils
import torchvision
import torchvision.transforms as transforms
from torch.utils.tensorboard import SummaryWriter
from torchsummary import summary

# additional libraries
import os
import shutil
import urllib.request
import zipfile
import time
import math
import numpy             as np
import matplotlib.pyplot as plt

################################################################################
#
# PARAMETERS
#
################################################################################

# data
DATA_DIR_1        = 'data'
DATA_DIR_2        = 'data/imagenet64'
DATA_DIR_TRAIN    = 'data/imagenet64/train'
DATA_DIR_TEST     = 'data/imagenet64/val'
DATA_FILE_TRAIN_1 = 'Train1.zip'
DATA_FILE_TRAIN_2 = 'Train2.zip'
DATA_FILE_TRAIN_3 = 'Train3.zip'
DATA_FILE_TRAIN_4 = 'Train4.zip'
DATA_FILE_TRAIN_5 = 'Train5.zip'
DATA_FILE_TEST_1  = 'Val1.zip'
DATA_URL_TRAIN_1  = 'https://github.com/arthurredfern/UT-Dallas-CS-6301-CNNs/raw/master/Data/Train1.zip'
DATA_URL_TRAIN_2  = 'https://github.com/arthurredfern/UT-Dallas-CS-6301-CNNs/raw/master/Data/Train2.zip'
DATA_URL_TRAIN_3  = 'https://github.com/arthurredfern/UT-Dallas-CS-6301-CNNs/raw/master/Data/Train3.zip'
DATA_URL_TRAIN_4  = 'https://github.com/arthurredfern/UT-Dallas-CS-6301-CNNs/raw/master/Data/Train4.zip'
DATA_URL_TRAIN_5  = 'https://github.com/arthurredfern/UT-Dallas-CS-6301-CNNs/raw/master/Data/Train5.zip'
DATA_URL_TEST_1   = 'https://github.com/arthurredfern/UT-Dallas-CS-6301-CNNs/raw/master/Data/Val1.zip'
DATA_BATCH_SIZE   = 512
DATA_NUM_WORKERS  = 4
DATA_NUM_CHANNELS = 3
DATA_NUM_CLASSES  = 100
DATA_RESIZE       = 64
DATA_CROP         = 56
DATA_MEAN         = (0.485, 0.456, 0.406)
DATA_STD_DEV      = (0.229, 0.224, 0.225)

# model
# add model parameters here

# training
# add training parameters here

# file
# add file parameters here

################################################################################
#
# DATA
#
################################################################################

# create a local directory structure for data storage
if (os.path.exists(DATA_DIR_1) == False):
    os.mkdir(DATA_DIR_1)
if (os.path.exists(DATA_DIR_2) == False):
    os.mkdir(DATA_DIR_2)
if (os.path.exists(DATA_DIR_TRAIN) == False):
    os.mkdir(DATA_DIR_TRAIN)
if (os.path.exists(DATA_DIR_TEST) == False):
    os.mkdir(DATA_DIR_TEST)

# download data
if (os.path.exists(DATA_FILE_TRAIN_1) == False):
    urllib.request.urlretrieve(DATA_URL_TRAIN_1, DATA_FILE_TRAIN_1)
if (os.path.exists(DATA_FILE_TRAIN_2) == False):
    urllib.request.urlretrieve(DATA_URL_TRAIN_2, DATA_FILE_TRAIN_2)
if (os.path.exists(DATA_FILE_TRAIN_3) == False):
    urllib.request.urlretrieve(DATA_URL_TRAIN_3, DATA_FILE_TRAIN_3)
if (os.path.exists(DATA_FILE_TRAIN_4) == False):
    urllib.request.urlretrieve(DATA_URL_TRAIN_4, DATA_FILE_TRAIN_4)
if (os.path.exists(DATA_FILE_TRAIN_5) == False):
    urllib.request.urlretrieve(DATA_URL_TRAIN_5, DATA_FILE_TRAIN_5)
if (os.path.exists(DATA_FILE_TEST_1) == False):
    urllib.request.urlretrieve(DATA_URL_TEST_1, DATA_FILE_TEST_1)

# extract data
with zipfile.ZipFile(DATA_FILE_TRAIN_1, 'r') as zip_ref:
    zip_ref.extractall(DATA_DIR_TRAIN)
with zipfile.ZipFile(DATA_FILE_TRAIN_2, 'r') as zip_ref:
    zip_ref.extractall(DATA_DIR_TRAIN)
with zipfile.ZipFile(DATA_FILE_TRAIN_3, 'r') as zip_ref:
    zip_ref.extractall(DATA_DIR_TRAIN)
with zipfile.ZipFile(DATA_FILE_TRAIN_4, 'r') as zip_ref:
    zip_ref.extractall(DATA_DIR_TRAIN)
with zipfile.ZipFile(DATA_FILE_TRAIN_5, 'r') as zip_ref:
    zip_ref.extractall(DATA_DIR_TRAIN)
with zipfile.ZipFile(DATA_FILE_TEST_1, 'r') as zip_ref:
    zip_ref.extractall(DATA_DIR_TEST)

# transforms
transform_train = transforms.Compose([transforms.RandomResizedCrop(DATA_CROP), transforms.RandomHorizontalFlip(p=0.5), transforms.ToTensor(), transforms.Normalize(DATA_MEAN, DATA_STD_DEV)])
transform_test  = transforms.Compose([transforms.Resize(DATA_RESIZE), transforms.CenterCrop(DATA_CROP), transforms.ToTensor(), transforms.Normalize(DATA_MEAN, DATA_STD_DEV)])

# data sets
dataset_train = torchvision.datasets.ImageFolder(DATA_DIR_TRAIN, transform=transform_train)
dataset_test  = torchvision.datasets.ImageFolder(DATA_DIR_TEST,  transform=transform_test)

# data loader
dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=DATA_BATCH_SIZE, shuffle=True,  num_workers=DATA_NUM_WORKERS, pin_memory=True, drop_last=True)
dataloader_test  = torch.utils.data.DataLoader(dataset_test,  batch_size=DATA_BATCH_SIZE, shuffle=False, num_workers=DATA_NUM_WORKERS, pin_memory=True, drop_last=True)

"""## RegNetX Network Building Block"""

################################################################################
#
# NETWORK BUILDING BLOCK
#
################################################################################

# Design a RegNetX-200MF network modified for the smaller image size as follows:
#  Set stride = 1 (instead of stride = 2) in the stem
#  Replace the first stride = 2 down sampling building block in the original network by a
# stride = 1 normal building block
#  The fully connected layer in the decoder outputs 100 classes instead of 1000classes
#  All of the other blocks in RegNetX-200MF stay the same
# The original RegNetX-200MF takes in 3x224x224 input images and generates Nx7x7 feature
# maps before the decoder, this modified RegNetX-200MF will take in 3x56x56 input images
# (cropped from the provided data set) and generate Nx7x7 feature maps before the decoder.
# Train the network using the training data to achieve the highest accuracy possible on the testing
# data. For reference, each epoch took ~ 112 s on Sep 27, 2020 using a free GPU runtime in
# Google Colab.

# The difference between RegNetX and RegNetY model is the addition of the Squeeze and Excitation Layer. RegNetY = RegNetX + SE

class Stem(nn.Module):
  def __init__(self, out_filters, in_filters=3):
    super(Stem, self).__init__()
    #changed stride = 2 to stride = 1
    self.conv3x3 = nn.Conv2d(in_filters, out_filters, kernel_size=3, stride=1, padding=1, bias=False)
    self.bn = nn.BatchNorm2d(out_filters)

  def forward(self, x):
    return F.relu(self.bn(self.conv3x3(x)))

#Downsampling used in first bottleneck block of every layer in RegNet
class Downsample(nn.Module):
  def __init__(self, in_filters, out_filters, stride):
    super(Downsample, self).__init__()

    self.conv1x1 = nn.Conv2d(in_filters, out_filters, kernel_size=1, stride=stride, bias=False)
    self.bn = nn.BatchNorm2d(out_filters)

  def forward(self, x):
    return self.bn(self.conv1x1(x))


#Bottleneck Residual Block in Layer
class Bottleneck(nn.Module):
  def __init__(self, in_filters, out_filters, bottleneck_ratio, group_size, stride=1):
    super(Bottleneck, self).__init__()

    #1x1 Bottleneck Convolution Block
    bottleneck_filters = in_filters // bottleneck_ratio
    self.conv1_1x1 = nn.Conv2d(in_filters, bottleneck_filters, kernel_size=1, bias=False) 
    self.bn1 = nn.BatchNorm2d(bottleneck_filters)

    #3x3 Convolution Block with Group Convolutions
    num_groups = bottleneck_filters // group_size
    self.conv2_3x3 = nn.Conv2d(bottleneck_filters, bottleneck_filters, kernel_size=3, stride=stride, padding=1, groups=num_groups, bias=False)
    self.bn2 = nn.BatchNorm2d(bottleneck_filters)

    #Downsample if stride=2
    self.downsample = Downsample(in_filters, out_filters, stride) if stride != 1 or in_filters != out_filters else None

    #1x1 Convolution Block
    self.conv3_1x1 = nn.Conv2d(bottleneck_filters, out_filters, kernel_size=1, bias=False)
    self.bn3 = nn.BatchNorm2d(out_filters)

  def forward(self, x):
    residual = x
    
    out = F.relu(self.bn1(self.conv1_1x1(x)))
    out = F.relu(self.bn2(self.conv2_3x3(out)))

    out = self.bn3(self.conv3_1x1(out))

    if self.downsample is not None:
      residual = self.downsample(x)
    
    out += residual
    out = F.relu(out)

    return out

class Layer(nn.Module):
  def __init__(self, in_filters, depth, width, bottleneck_ratio, group_size):
    super(Layer, self).__init__()
    
    self.layers = []

    #Total bottleneck blocks in a layer = Depth d
    for i in range(depth):
      stride = 2 if i == 0 else 1
      bottleneck = Bottleneck(in_filters, width, bottleneck_ratio, group_size, stride)
      self.layers.append(bottleneck)
      in_filters = width

    self.layers = nn.Sequential(*self.layers)
  
  def forward(self, x):
    out = self.layers(x)
    return out

class Head(nn.Module):

  def __init__(self, in_filters, classes):

    super(Head, self).__init__()

    self.avgpool = nn.AdaptiveAvgPool2d(output_size=1)
    self.fc = nn.Linear(in_filters, classes)

  def forward(self, x):

    out = self.avgpool(x)
    out = torch.flatten(out, 1)
    out = self.fc(out)
    return out

class RegNet(nn.Module):
  def __init__(self, paramaters, classes=100):
    super(RegNet, self).__init__()

    #Model paramater initialization
    self.in_filters = 32
    self.w, self.d, self.b, self.g = parameters
    self.num_layers = 4

    #Stem Part of the generic ResNeX architecture
    self.stem = Stem(self.in_filters)
    self.body = []

    for i in range(self.num_layers):
      layer = Layer(self.in_filters, self.d[i], self.w[i], self.b, self.g)
      self.body.append(layer)
      self.in_filters = self.w[i]
    
    #Body Part: Four Layers containing bottleneck residual blocks
    self.body = nn.Sequential(*self.body)

    #Head Part: Classification Step FC + AveragePool
    self.head = Head(self.w[-1], classes)

  def forward(self, x):

    out = self.stem(x)
    out = self.body(out)
    out = self.head(out)
    return out

"""## Model Training, Validation, Accuracy, and Check Point functions"""

#checkpoint paths
saved_path = 'trained_models'
log_path = 'tensorboard/regnet'

def adjust_learning_rate(optimizer, epoch, lr):
    """Sets the learning rate to the initial LR decayed by 10 every 30 epochs"""
    lr = lr * (0.1 ** (epoch // 30))
    for param_group in optimizer.param_groups:
        param_group['lr'] = lr

def save_checkpoint(state, is_best, saved_path, filename="checkpoint.pth.tar"):
    file_path = os.path.join(saved_path, filename)
    torch.save(state, file_path)
    if is_best:
        shutil.copyfile(file_path, os.path.join(saved_path, "best_checkpoint.pth.tar"))


def train(train_loader, model, criterion, optimizer, epoch, writer):
    batch_time = AverageMeter("Time", ":6.3f")
    data_time = AverageMeter("Data", ":6.3f")
    losses = AverageMeter("Loss", ":.4e")
    top1 = AverageMeter("Acc@1", ":6.2f")
    progress = ProgressMeter(
        len(train_loader),
        [batch_time, data_time, losses, top1],
        prefix="Epoch: [{}]".format(epoch))
    model.train()
    end = time.time()
    num_iter_per_epoch = len(train_loader)

    for i, (images, target) in enumerate(train_loader):
        data_time.update(time.time() - end)

        if torch.cuda.is_available():
            images = images.cuda()
            target = target.cuda()

        # compute output
        output = model(images)
        # print(output)
        loss = criterion(output, target)

        # measure accuracy and record loss
        acc1, _ = accuracy(output, target, topk=(1, 5))
        losses.update(loss.detach().item(), images.size(0))
        top1.update(acc1[0], images.size(0))
        

        writer.add_scalar('Train/Loss', losses.avg, epoch * num_iter_per_epoch + i)
        writer.add_scalar('Train/Top1_acc', top1.avg, epoch * num_iter_per_epoch + i)
        # writer.add_scalar('Train/Top5_acc', top5.avg, epoch * num_iter_per_epoch + i)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        # measure elapsed time
        batch_time.update(time.time() - end)
        end = time.time()

        if i % 10 == 0:
            progress.display(i)
    return top1.val, losses.val

def validate(val_loader, model, criterion, epoch, writer):
    batch_time = AverageMeter("Time", ":6.3f")
    losses = AverageMeter("Loss", ":.4e")
    top1 = AverageMeter("Acc@1", ":6.2f")
    progress = ProgressMeter(
        len(val_loader),
        [batch_time, losses, top1],
        prefix="Test: ")

    # switch to evaluate mode
    model.eval()

    with torch.no_grad():
        end = time.time()
        for i, (images, target) in enumerate(val_loader):
            if torch.cuda.is_available():
                images = images.cuda()
                target = target.cuda()

            # compute output
            output = model(images)
            loss = criterion(output, target)

            # measure accuracy and record loss
            acc1, _ = accuracy(output, target, topk=(1, 5))
            losses.update(loss.item(), images.size(0))
            top1.update(acc1[0], images.size(0))

            # measure elapsed time
            batch_time.update(time.time() - end)
            end = time.time()

            if i % 10 == 0:
                progress.display(i)

        print(" * Accuracy {top1.avg:.3f}"
              .format(top1=top1))
        
        writer.add_scalar('Test/Loss', losses.avg, epoch)
        writer.add_scalar('Test/Top1_acc', top1.avg, epoch)
        # writer.add_scalar('Test/Top5_acc', top5.avg, epoch)
    return top1.avg, losses.avg

class AverageMeter(object):
    """Computes and stores the average and current value"""

    def __init__(self, name, fmt=":f"):
        self.name = name
        self.fmt = fmt
        self.reset()

    def reset(self):
        self.val = 0
        self.avg = 0
        self.sum = 0
        self.count = 0

    def update(self, val, n=1):
        self.val = val
        self.sum += val * n
        self.count += n
        self.avg = self.sum / self.count

    def __str__(self):
        fmtstr = "{name} {val" + self.fmt + "} ({avg" + self.fmt + "})"
        return fmtstr.format(**self.__dict__)


class ProgressMeter(object):
    def __init__(self, num_batches, meters, prefix=""):
        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)
        self.meters = meters
        self.prefix = prefix

    def display(self, batch):
        entries = [self.prefix + self.batch_fmtstr.format(batch)]
        entries += [str(meter) for meter in self.meters]
        print("\t".join(entries))

    def _get_batch_fmtstr(self, num_batches):
        num_digits = len(str(num_batches // 1))
        fmt = "{:" + str(num_digits) + "d}"
        return "[" + fmt + "/" + fmt.format(num_batches) + "]"



def accuracy(output, target, topk=(1,)):
    """Computes the accuracy over the k top predictions for the specified values of k"""
    with torch.no_grad():
        maxk = max(topk)
        batch_size = target.size(0)

        _, pred = output.topk(maxk, 1, True, True)
        pred = pred.t()
        correct = pred.eq(target.view(1, -1).expand_as(pred))

        res = []
        for k in topk:
            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)
            res.append(correct_k.mul_(100.0 / batch_size))
        return res

def main(model, batch_size, epochs, lr, weight_decay):
    num_gpus = 1
    if torch.cuda.is_available():
        num_gpus = torch.cuda.device_count()
        torch.cuda.manual_seed(123)
    else:
        torch.manual_seed(123)

    training_params = {"batch_size": batch_size * num_gpus,
                       "shuffle": True,
                       "drop_last": True,
                       "num_workers": 12}

    test_params = {"batch_size": batch_size//10,
                   "shuffle": False,
                   "drop_last": False,
                   "num_workers": 12}
   
    if os.path.isdir(log_path):
        shutil.rmtree(log_path)
    os.makedirs(log_path)

    if not os.path.isdir(saved_path):
        os.makedirs(saved_path)
    writer = SummaryWriter(log_path)

    dummy_input = torch.randn((1, 3, DATA_CROP, DATA_CROP))
    writer.add_graph(model, dummy_input)
    summary(model, (3, DATA_CROP, DATA_CROP), device="cpu")

    if torch.cuda.is_available():
        model = nn.DataParallel(model)
        model = model.cuda()

    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)
    best_acc1 = 0
    model.train()
    val_acc = [] 
    train_acc = []
    train_los = []
    val_los = []
    for epoch in range(epochs):
        adjust_learning_rate(optimizer, epoch, lr)
        t_acc, t_los = train(dataloader_train, model, criterion, optimizer, epoch, writer)
        acc1, test_l = validate(dataloader_test, model, criterion, epoch, writer)

        is_best = acc1 > best_acc1
        best_acc1 = max(acc1, best_acc1)
        train_acc.append(t_acc)
        train_los.append(t_los)
        val_acc.append(acc1)
        val_los.append(test_l)
        save_checkpoint({
            "epoch": epoch + 1,
            "state_dict": model.state_dict(),
            "best_acc1": best_acc1,
            "optimizer": optimizer.state_dict(),
        }, is_best, saved_path)
    return train_acc,train_los, val_acc, val_los

"""# Generate parameters for regnet"""

def generate_parameters_regnet(D, w0, wa, wm, b, g):

  u = w0 + wa * np.arange(D) # Equation 1
  s = np.log(u / w0) / np.log(wm) # Equation 2

  s = np.round(s) #Rounding the possible block sizes s
  w = w0 * np.power(wm, s) # Equation 3
  w = np.round(w / 8) * 8 # Make all the width list divisible by 8

  w, d = np.unique(w.astype(np.int), return_counts=True) #Finding depth and width lists.

  gtemp = np.minimum(g, w//b)
  w = (np.round(w // b / gtemp) * gtemp).astype(int) #To make all the width compatible with group sizes of the 3x3 convolutional layers
  g = np.unique(gtemp // b)[0]

  return (w, d, b, g)

#Section 1: Include hyper parameters for RegNetX200MF

# Network Depth D = 13
# Slope Parameter wa = 36
# Initial width w0 = 24
# Quantization parameter wm = 2.5
# Bottleneck ratio b = 1
# Group Width g = 8, Group Size: Range::{1, 2, 4, 8, 16, 32} OR {16, 24, 32, 40, 48, 56, 64}')

DEPTH = 13
W0 = 24
WA = 36
WM = 2.49
GROUP_W = 8
B = 1
G = 8   

parameters = generate_parameters_regnet(DEPTH, W0, WA, WM, B, G)
model = RegNet(parameters, DATA_NUM_CLASSES)

"""## Section 2 – Training"""

#Section 2: Include hyper parameters associated to training and optimizer
# TRAIN:
#   DATASET: imagenet
#   IM_SIZE: 56
#   BATCH_SIZE: 512

#Optimizer: Adam, hyperparameters 
EPOCHS = 55
LR = 0.005
WEIGHT_DECAY = 0.0001

print('Model Summary:>>\n')
st = time.time()

train_accuracy, train_loss, test_accuracy, test_loss = main(model,DATA_BATCH_SIZE, EPOCHS, LR, WEIGHT_DECAY )

print(f'\nTotal time: --- {time.time() - st} seconds ---')

"""# Section 2: Plots"""

fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))

axes[0].plot(list(range(1, EPOCHS+1)), train_loss)
axes[0].set_xlabel('Epoch')
axes[0].set_ylabel('Loss')
axes[0].set_title('Train loss over epochs')
fig.tight_layout()

fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))


axes[0].plot(list(range(1, EPOCHS+1)), test_accuracy)
axes[0].set_xlabel('Epoch')
axes[0].set_ylabel('Accuracy')
axes[0].set_title('Test accuracy over epochs')

fig.tight_layout()

# log_path = 'tensorboard/regnet'
# os.makedirs(log_path)

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard

# %tensorboard --logdir /content/tensorboard/regnet/

